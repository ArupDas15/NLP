{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_final_project_custom_search_application.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90897dfddb1c481babe140a44b4b8f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7e350919d784be8af340073e431d1c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4da89f38ca8d4ac092d2913b1798d08e",
              "IPY_MODEL_4281845ff53a41418f8dd17995863184",
              "IPY_MODEL_2f83de012ae24037addd34b15c8dc142",
              "IPY_MODEL_1967db895e0d4f3094c54b1ce24c80fd"
            ]
          }
        },
        "d7e350919d784be8af340073e431d1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4da89f38ca8d4ac092d2913b1798d08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "state": {
            "_view_name": "TextareaView",
            "style": "IPY_MODEL_47f1db769d6a4ce1a0bec85bef6ec893",
            "rows": null,
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextareaModel",
            "placeholder": "Your query",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Best papers on aerodynamics",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dba0281c9a354505a9dfc974abcb5998"
          }
        },
        "4281845ff53a41418f8dd17995863184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "BM25",
              "BM25+LSA",
              "LSA"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_b6d1cfb67df741b893fda4f22f8c71c0",
            "_dom_classes": [],
            "description": "Algorithm: ",
            "_model_name": "DropdownModel",
            "index": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7150060a8164aa69fcd312e1f22c63e"
          }
        },
        "2f83de012ae24037addd34b15c8dc142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "1",
              "2",
              "3",
              "4",
              "5"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_3fea55e0e2bd496382e5d794e26b9374",
            "_dom_classes": [],
            "description": "k:",
            "_model_name": "DropdownModel",
            "index": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_949eda08a0624c8ea9ae52e7025b285a"
          }
        },
        "1967db895e0d4f3094c54b1ce24c80fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_b05715555552474ab3bf759a9964859e",
            "_dom_classes": [],
            "description": "Search",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "Click me",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_de8cc7c1534545a3bee602739d528b24",
            "_model_module": "@jupyter-widgets/controls",
            "icon": "check"
          }
        },
        "47f1db769d6a4ce1a0bec85bef6ec893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dba0281c9a354505a9dfc974abcb5998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6d1cfb67df741b893fda4f22f8c71c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7150060a8164aa69fcd312e1f22c63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fea55e0e2bd496382e5d794e26b9374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "949eda08a0624c8ea9ae52e7025b285a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b05715555552474ab3bf759a9964859e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de8cc7c1534545a3bee602739d528b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39604baee01e402da407a3b5df22d845": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Relevant documents:\n1066 137 1333 \n\nThe contents of these documents are:\n1: wind tunnel measurements of aerodynamic damping derivatives of a launch vehicle vibrating ...\n2: the generation of sound by aerodynamic means .   a summary is given of some of the more im...\n3: aerodynamic forces on wings in non-uniform motion .   the problem of determining the aerod...\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_46383b8af63545bea81ad056e356c819",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "46383b8af63545bea81ad056e356c819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "13EoaCw5zS5x"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxggxzbjg8Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8957d02-1c8c-4517-ebd0-7edfa87b3115"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Datasets/cranfield.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Datasets/cranfield.zip\n",
            "  inflating: cranfield/.DS_Store     \n",
            "  inflating: cranfield/cran_docs.json  \n",
            "  inflating: cranfield/cran_qrels.json  \n",
            "  inflating: cranfield/cran_queries.json  \n",
            "  inflating: cranfield/README.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHnODNl79Pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5180940-5b50-42ad-b94d-14b6d6a304ef"
      },
      "source": [
        "!pip install rank_bm25"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading https://files.pythonhosted.org/packages/16/5a/23ed3132063a0684ea66fb410260c71c4ffda3b99f8f1c021d1e245401b5/rank_bm25-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rank_bm25) (1.19.5)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTu-YRq0fw9z",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc018f0-a1fe-4ab1-da4b-26658a76e1a2"
      },
      "source": [
        "#@title Python libraries used in the project\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import json\n",
        "from rank_bm25 import BM25Okapi\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UndOvWhNf6Ue",
        "cellView": "form"
      },
      "source": [
        "#@title Code for data preprocessing\n",
        "def data_preprocess(doc):\n",
        "  tokens = word_tokenize(doc)\n",
        "  # convert to lower case \n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  # remove punctuation from each word\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  # filter out stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  # stemming of words\n",
        "  porter = PorterStemmer()\n",
        "  stemmed = [porter.stem(word) for word in words]\n",
        "  return stemmed"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPynd7wLhHuX",
        "cellView": "form"
      },
      "source": [
        "#@title Code for evaluation\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Add your import statements here\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "\n",
        "class Evaluation():\n",
        "    def __init__(self):\n",
        "      self.qr=None #This dictionary holds the list of relevant documents for a particular query\n",
        "    def build_qr(self,q_rels):\n",
        "      #This function populates the self.qr dictionary which has relevant document lists as values and\n",
        "      #query ids as keys of the dictionary\n",
        "      qr = defaultdict(list)\n",
        "      for dc in q_rels:\n",
        "        qr[int(dc['query_num'])].append(int(dc['id']))\n",
        "      self.qr=qr\n",
        "    def get_docid(self,query_id,qrels):\n",
        "      result = list(filter(lambda query: query['query_num'] == str(query_id), qrels))\n",
        "      doc_id = []\n",
        "      for d in result:\n",
        "        for k, v in d.items():\n",
        "          if k == \"id\":\n",
        "            doc_id.append(v)\n",
        "      return doc_id\n",
        "\n",
        "    def get_rel_score(self, query_id,element, qrels):\n",
        "      result = list(filter(lambda query: query['query_num'] == str(query_id), qrels))\n",
        "      doc_id = []\n",
        "      rel_score = []\n",
        "      for d in result:\n",
        "        for k, v in d.items():\n",
        "          if k == \"id\":\n",
        "            doc_id.append(v)\n",
        "          if k == \"position\":\n",
        "            # Measuring the relevance score in a scale of 0-3 where integer with higher value has greater relevance\n",
        "            rel_score.append(4-int(v))\n",
        "\n",
        "      relavant_score = rel_score[doc_id.index(element)]\n",
        "      return relavant_score\n",
        "\n",
        "    def queryPrecision(self, query_doc_IDs_ordered, query_id, true_doc_IDs, k):\n",
        "      \"\"\"\n",
        "      Computation of precision of the Information Retrieval System\n",
        "      at a given value of k for a single query\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of integers denoting the IDs of documents in\n",
        "        their predicted order of relevance to a query\n",
        "      arg2 : int\n",
        "        The ID of the query in question\n",
        "      arg3 : list\n",
        "        The list of IDs of documents relevant to the query (ground truth)\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The precision value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      precision = 0\n",
        "\n",
        "      #Fill in code here\n",
        "      count = 1\n",
        "      for element in query_doc_IDs_ordered:\n",
        "        # Find the number of relevant documents in top k results\n",
        "        if count <= k:\n",
        "          # if the document is present in the relevant document list then increment precision count by 1.\n",
        "          if str(element) in true_doc_IDs:\n",
        "            precision = precision + 1\n",
        "        count = count + 1\n",
        "      if k== 0:\n",
        "        precision = 1\n",
        "      else:\n",
        "        # Dividing precision by number of documents retrieved at rank 'k'\n",
        "        precision = precision / k\n",
        "\n",
        "      return precision\n",
        "\n",
        "\n",
        "    def meanPrecision(self, doc_IDs_ordered, query_ids, qrels, k):\n",
        "      \"\"\"\n",
        "      Computation of precision of the Information Retrieval System\n",
        "      at a given value of k, averaged over all the queries\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of lists of integers where the ith sub-list is a list of IDs\n",
        "        of documents in their predicted order of relevance to the ith query\n",
        "      arg2 : list\n",
        "        A list of IDs of the queries for which the documents are ordered\n",
        "      arg3 : list\n",
        "        A list of dictionaries containing document-relevance\n",
        "        judgements - Refer cran_qrels.json for the structure of each\n",
        "        dictionary\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The mean precision value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      meanPrecision = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      n = 0\n",
        "      sum = 0\n",
        "      for l in doc_IDs_ordered:\n",
        "        if n==len(query_ids):break\n",
        "        doc_id = self.get_docid(query_ids[n], qrels)\n",
        "        sum = sum + self.queryPrecision(l, query_ids[n], doc_id, k)\n",
        "        n = n + 1\n",
        "      if len(doc_IDs_ordered) == 0:\n",
        "        meanPrecision = 1\n",
        "      else:\n",
        "        # Finding the average of all precision values corresponding to different queries\n",
        "        meanPrecision = sum / len(doc_IDs_ordered)\n",
        "      return meanPrecision\n",
        "\n",
        "\n",
        "    def queryRecall(self, query_doc_IDs_ordered, query_id, true_doc_IDs, k):\n",
        "      \"\"\"\n",
        "      Computation of recall of the Information Retrieval System\n",
        "      at a given value of k for a single query\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of integers denoting the IDs of documents in\n",
        "        their predicted order of relevance to a query\n",
        "      arg2 : int\n",
        "        The ID of the query in question\n",
        "      arg3 : list\n",
        "        The list of IDs of documents relevant to the query (ground truth)\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The recall value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      recall = 0\n",
        "\n",
        "      #Fill in code here\n",
        "      count = 1\n",
        "      for element in query_doc_IDs_ordered:\n",
        "        # Find the number of relevant documents in top k results\n",
        "        if count <= k:\n",
        "          # if the document is present in the relevant document list then increment recall count by 1.\n",
        "          if str(element) in true_doc_IDs:\n",
        "            recall = recall + 1\n",
        "        count = count + 1\n",
        "      if len(true_doc_IDs) == 0:\n",
        "        recall = 1\n",
        "      else:\n",
        "        # Dividing recall by number of relevant documents\n",
        "        recall = recall / len(true_doc_IDs)\n",
        "\n",
        "      return recall\n",
        "\n",
        "\n",
        "    def meanRecall(self, doc_IDs_ordered, query_ids, qrels, k):\n",
        "      \"\"\"\n",
        "      Computation of recall of the Information Retrieval System\n",
        "      at a given value of k, averaged over all the queries\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of lists of integers where the ith sub-list is a list of IDs\n",
        "        of documents in their predicted order of relevance to the ith query\n",
        "      arg2 : list\n",
        "        A list of IDs of the queries for which the documents are ordered\n",
        "      arg3 : list\n",
        "        A list of dictionaries containing document-relevance\n",
        "        judgements - Refer cran_qrels.json for the structure of each\n",
        "        dictionary\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The mean recall value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      meanRecall = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      n = 0\n",
        "      sum = 0\n",
        "      for l in doc_IDs_ordered:\n",
        "        if n==len(query_ids):break\n",
        "        doc_id = self.get_docid(query_ids[n], qrels)\n",
        "        sum = sum + self.queryRecall(l,query_ids[n],doc_id,k)\n",
        "        n = n + 1\n",
        "      if len(doc_IDs_ordered) == 0:\n",
        "        meanRecall = 1\n",
        "      else:\n",
        "        # Finding the average of all recall values corresponding to different queries\n",
        "        meanRecall = sum / len(doc_IDs_ordered)\n",
        "      return meanRecall\n",
        "\n",
        "    def queryFscore(self, query_doc_IDs_ordered, query_id, true_doc_IDs, k):\n",
        "      \"\"\"\n",
        "      Computation of fscore of the Information Retrieval System\n",
        "      at a given value of k for a single query\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of integers denoting the IDs of documents in\n",
        "        their predicted order of relevance to a query\n",
        "      arg2 : int\n",
        "        The ID of the query in question\n",
        "      arg3 : list\n",
        "        The list of IDs of documents relevant to the query (ground truth)\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The fscore value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      fscore = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      precision = self.queryPrecision(query_doc_IDs_ordered, query_id, true_doc_IDs, k)\n",
        "      recall = self.queryRecall(query_doc_IDs_ordered, query_id, true_doc_IDs, k)\n",
        "      # This will happen when there are no relevant documents in top k results\n",
        "      if precision + recall == 0:\n",
        "        fscore = 0\n",
        "      else:\n",
        "        fscore = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "      return fscore\n",
        "\n",
        "    def meanFscore(self, doc_IDs_ordered, query_ids, qrels, k):\n",
        "      \"\"\"\n",
        "      Computation of fscore of the Information Retrieval System\n",
        "      at a given value of k, averaged over all the queries\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of lists of integers where the ith sub-list is a list of IDs\n",
        "        of documents in their predicted order of relevance to the ith query\n",
        "      arg2 : list\n",
        "        A list of IDs of the queries for which the documents are ordered\n",
        "      arg3 : list\n",
        "        A list of dictionaries containing document-relevance\n",
        "        judgements - Refer cran_qrels.json for the structure of each\n",
        "        dictionary\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The mean fscore value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      meanFscore = -1\n",
        "\n",
        "      # Fill in code here\n",
        "      n = 0\n",
        "      sum = 0\n",
        "      for l in doc_IDs_ordered:\n",
        "        if n==len(query_ids):break\n",
        "        doc_id = self.get_docid(query_ids[n], qrels)\n",
        "        sum = sum + self.queryFscore(l, query_ids[n], doc_id, k)\n",
        "        n = n + 1\n",
        "      # Finding the average of all fscore values corresponding to different queries\n",
        "      meanFscore = sum / len(doc_IDs_ordered)\n",
        "      return meanFscore\n",
        "\n",
        "\n",
        "    def queryNDCG(self, query_doc_IDs_ordered, query_id, true_doc_IDs, k):\n",
        "      \"\"\"\n",
        "      Computation of nDCG of the Information Retrieval System\n",
        "      at given value of k for a single query\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of integers denoting the IDs of documents in\n",
        "        their predicted order of relevance to a query\n",
        "      arg2 : int\n",
        "        The ID of the query in question\n",
        "      arg3 : list\n",
        "        The list of IDs of documents relevant to the query (ground truth)\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The nDCG value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      nDCG = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      DCG = 0\n",
        "      IDCG = 0\n",
        "      #path=os.path.join(os.getcwd(),\"cranfield\",\"cran_qrels.json\")\n",
        "      qrels = json.load(open('/content/cranfield/cran_qrels.json', 'r'))[:]\n",
        "      count = 1\n",
        "      for element in query_doc_IDs_ordered:\n",
        "        if count <= k:\n",
        "          if str(element) in true_doc_IDs:\n",
        "            DCG = DCG + (self.get_rel_score(query_id, str(element), qrels) / math.log2(query_doc_IDs_ordered.index(element) + 2))\n",
        "          count = count + 1\n",
        "      count = 1\n",
        "      for element in true_doc_IDs:\n",
        "        if count <= k:\n",
        "          IDCG = IDCG + (self.get_rel_score(query_id,element,qrels) / math.log2(count + 1))\n",
        "          count = count + 1\n",
        "      # When there are no documents in the ideally relevant to the query then there are no documents to display.\n",
        "      # Thus the relevance score is 1.\n",
        "      if IDCG == 0:\n",
        "        IDCG = 1\n",
        "      nDCG = DCG / IDCG\n",
        "      return nDCG\n",
        "\n",
        "\n",
        "    def meanNDCG(self, doc_IDs_ordered, query_ids, qrels, k):\n",
        "      \"\"\"\n",
        "      Computation of nDCG of the Information Retrieval System\n",
        "      at a given value of k, averaged over all the queries\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of lists of integers where the ith sub-list is a list of IDs\n",
        "        of documents in their predicted order of relevance to the ith query\n",
        "      arg2 : list\n",
        "        A list of IDs of the queries for which the documents are ordered\n",
        "      arg3 : list\n",
        "        A list of dictionaries containing document-relevance\n",
        "        judgements - Refer cran_qrels.json for the structure of each\n",
        "        dictionary\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The mean nDCG value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      meanNDCG = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      n = 0\n",
        "      sum = 0\n",
        "      for l in doc_IDs_ordered:\n",
        "        if n==len(query_ids): break\n",
        "        true_doc_IDs = self.get_docid(query_ids[n], qrels)\n",
        "        nDCG=self.queryNDCG(l, query_ids[n], true_doc_IDs, k)\n",
        "        sum = sum + nDCG\n",
        "        n = n + 1\n",
        "      # Finding the average of all nDCG values corresponding to different queries\n",
        "      meanNDCG = sum/len(doc_IDs_ordered)\n",
        "      return meanNDCG\n",
        "\n",
        "\n",
        "    def queryAveragePrecision(self, query_doc_IDs_ordered, query_id, true_doc_IDs, k):\n",
        "      \"\"\"\n",
        "      Computation of average precision of the Information Retrieval System\n",
        "      at a given value of k for a single query (the average of precision@i\n",
        "      values for i such that the ith document is truly relevant)\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of integers denoting the IDs of documents in\n",
        "        their predicted order of relevance to a query\n",
        "      arg2 : int\n",
        "        The ID of the query in question\n",
        "      arg3 : list\n",
        "        The list of documents relevant to the query (ground truth)\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The average precision value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      avgPrecision = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      pdl=query_doc_IDs_ordered\n",
        "      rdl=true_doc_IDs\n",
        "      for j in range(len(pdl)):\n",
        "        if pdl[j] in rdl:\n",
        "          pdl[j] = 1\n",
        "        else:\n",
        "          pdl[j] = 0\n",
        "      ap = 0\n",
        "      for j in range(len(pdl)):\n",
        "        ap += (sum(pdl[:(j + 1)]) * 1.0 / (j + 1))\n",
        "      ap /= len(pdl)\n",
        "      avgPrecision=ap\n",
        "      return avgPrecision\n",
        "\n",
        "\n",
        "    def meanAveragePrecision(self, doc_IDs_ordered, query_ids, q_rels, k):\n",
        "      \"\"\"\n",
        "      Computation of MAP of the Information Retrieval System\n",
        "      at given value of k, averaged over all the queries\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      arg1 : list\n",
        "        A list of lists of integers where the ith sub-list is a list of IDs\n",
        "        of documents in their predicted order of relevance to the ith query\n",
        "      arg2 : list\n",
        "        A list of IDs of the queries\n",
        "      arg3 : list\n",
        "        A list of dictionaries containing document-relevance\n",
        "        judgements - Refer cran_qrels.json for the structure of each\n",
        "        dictionary\n",
        "      arg4 : int\n",
        "        The k value\n",
        "\n",
        "      Returns\n",
        "      -------\n",
        "      float\n",
        "        The MAP value as a number between 0 and 1\n",
        "      \"\"\"\n",
        "\n",
        "      meanAveragePrecision = -1\n",
        "\n",
        "      #Fill in code here\n",
        "      MAP = 0\n",
        "      # preprocess q_rels\n",
        "      self.build_qr(q_rels)\n",
        "      qr = self.qr\n",
        "\n",
        "      for i in range(len(query_ids)):\n",
        "        # print(len(doc_IDs_ordered_all),len(query_ids))\n",
        "        pdl = doc_IDs_ordered[i][:k]\n",
        "        rdl = qr[int(query_ids[i])]\n",
        "        #print(pdl[:10], rdl)\n",
        "        for j in range(len(pdl)):\n",
        "          if pdl[j] in rdl:\n",
        "            pdl[j] = 1\n",
        "          else:\n",
        "            pdl[j] = 0\n",
        "        ap = 0\n",
        "        for j in range(len(pdl)):\n",
        "          ap += (sum(pdl[:(j + 1)]) * 1.0 / (j + 1))\n",
        "        ap /= len(pdl)\n",
        "        MAP += ap\n",
        "      MAP /= len(query_ids)\n",
        "      meanAveragePrecision=MAP\n",
        "\n",
        "\n",
        "      return meanAveragePrecision\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pX1_aewCf8kD"
      },
      "source": [
        "#@title Function for old method\n",
        "def train_old(k):\n",
        "  #without SVD\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  #print(len(dids),len(qids))\n",
        "  qrels=json.load(open('/content/cranfield/cran_qrels.json', 'r'))\n",
        "  eval=Evaluation()\n",
        "  vectorizer = TfidfVectorizer(tokenizer=data_preprocess,stop_words=None, \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True,max_df=0.6)\n",
        "  dvecs1=vectorizer.fit_transform(docs).todense()\n",
        "  qvecs1=vectorizer.transform(qrs).todense()\n",
        "  #print(dvecs1.shape,qvecs1.shape)\n",
        "  B=sklearn.metrics.pairwise.cosine_similarity(qvecs1,dvecs1)\n",
        "\n",
        "  pred_ids=np.zeros((255,k),dtype=int)\n",
        "  for i in range(0,225):\n",
        "    x=np.argsort(B[i]).T[::-1][:k]\n",
        "    j=0\n",
        "    for y in x:\n",
        "      pred_ids[i][j]=dids[y]\n",
        "      j+=1\n",
        "  pdl=pred_ids.tolist()\n",
        "\n",
        "  results1=[]\n",
        "  for i in range(20):\n",
        "    s=i*10\n",
        "    e=s+10\n",
        "    results1.append([eval.meanAveragePrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanNDCG(pdl[s:e],qids[s:e],qrels,k),eval.meanPrecision(pdl[s:e],qids[s:e],qrels,k)])\n",
        "  #print(results1)\n",
        "  rf1=open('Tfidf_only_cosineSim.csv','w')\n",
        "  rf1.write('MAP,NDCG,MP\\n')\n",
        "  for x in results1:\n",
        "    rf1.write(str(x[0])+','+str(x[1])+','+str(x[2])+'\\n')\n",
        "  rf1.close()\n",
        "  print('Using old method- k: '+str(k)+' nDCG: '+str(eval.meanNDCG(pdl,qids,qrels,k)))\n",
        "  return results1,eval.meanNDCG(pdl,qids,qrels,k),eval.meanAveragePrecision(pdl,qids,qrels,k),eval.meanRecall(pdl,qids,qrels,k),eval.meanFscore(pdl,qids,qrels,k)\n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKSe9GyLgDmt",
        "cellView": "form"
      },
      "source": [
        "#@title Function for new  method using LSA\n",
        "def train_new(k):\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body']+' '+item['title'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  #print(len(dids),len(qids))\n",
        "  #k=5\n",
        "  vectorizer = TfidfVectorizer(tokenizer=data_preprocess,stop_words=None, \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True,max_df=0.9)\n",
        "  svd_model = TruncatedSVD(n_components=325,         \n",
        "                          algorithm='randomized',\n",
        "                          n_iter=10)\n",
        "  svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "                              ('svd', svd_model)])\n",
        "  dvecs=svd_transformer.fit_transform(docs)\n",
        "  from scipy.sparse import csr_matrix\n",
        "  #qvecs_qe=np.dot(vectorizer.transform(qrs).todense(),wsim)\n",
        "  #qvecs=np.dot(qvecs_qe,svd_model.components_.T)\n",
        "  qvecs=svd_transformer.transform(qrs)\n",
        "  #print(qvecs.shape)\n",
        "  A=sklearn.metrics.pairwise.cosine_similarity(qvecs,dvecs)\n",
        "  pred_ids=np.zeros((255,k),dtype=int)\n",
        "  for i in range(0,225):\n",
        "    x=np.argsort(A[i]).T[::-1][:k]\n",
        "    j=0\n",
        "    for y in x:\n",
        "      pred_ids[i][j]=dids[y]\n",
        "      j+=1\n",
        "  pdl=pred_ids.tolist()\n",
        "  qrels=json.load(open('/content/cranfield/cran_qrels.json', 'r'))\n",
        "  eval=Evaluation()\n",
        "  results=[]\n",
        "  for i in range(20):\n",
        "    s=i*10\n",
        "    e=s+10\n",
        "    results.append([eval.meanAveragePrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanNDCG(pdl[s:e],qids[s:e],qrels,k),eval.meanPrecision(pdl[s:e],qids[s:e],qrels,k)])\n",
        "  print('Using new method using LSA- k: '+str(k)+' nDCG: '+str(eval.meanNDCG(pdl,qids,qrels,k)))\n",
        "  rf=open('SVD_cosineSim.csv','w')\n",
        "  rf.write('MAP,NDCG,MP\\n')\n",
        "  for x in results:\n",
        "    rf.write(str(x[0])+','+str(x[1])+','+str(x[2])+'\\n')\n",
        "  rf.close()\n",
        "  return results,eval.meanNDCG(pdl,qids,qrels,k),eval.meanAveragePrecision(pdl,qids,qrels,k),eval.meanRecall(pdl,qids,qrels,k),eval.meanFscore(pdl,qids,qrels,k)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LROakM6VFx",
        "cellView": "form"
      },
      "source": [
        "#@title Using both bm25 and LSA\n",
        "def data_preprocess1(docs):\n",
        "  doc_list=[]\n",
        "  for every_doc in docs:\n",
        "    tokens = word_tokenize(every_doc)\n",
        "    # convert to lower case \n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    # remove punctuation from each word\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    stripped = [w.translate(table) for w in tokens]\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    words = [word for word in stripped if word.isalpha()]\n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    # stemming of words\n",
        "    porter = PorterStemmer()\n",
        "    stemmed = [porter.stem(word) for word in tokens]\n",
        "    doc_list.append(stemmed)\n",
        "  return doc_list\n",
        "def get_wsim():\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body']+' '+item['title'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  #print(len(dids),len(qids))\n",
        "  #k=5\n",
        "  vectorizer = TfidfVectorizer(tokenizer=data_preprocess,stop_words=None, \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True,max_df=0.9)\n",
        "  svd_model = TruncatedSVD(n_components=325,         \n",
        "                          algorithm='randomized',\n",
        "                          n_iter=10)\n",
        "  svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "                              ('svd', svd_model)])\n",
        "  dvecs=svd_transformer.fit_transform(docs)\n",
        "  wsim=sklearn.metrics.pairwise.cosine_similarity(svd_model.components_.T,svd_model.components_.T)\n",
        "  return wsim,vectorizer\n",
        "\n",
        "def train_mixed(k,k1=1,k2=1):\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body']+' '+item['title'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  tot_query = len(qids)\n",
        "  pred_ids=np.zeros((tot_query,k),dtype=int)\n",
        "  tokenized_corpus = data_preprocess1(docs)\n",
        "  tokenized_query = data_preprocess1(qrs)\n",
        "  bm25 = BM25Okapi(tokenized_corpus)\n",
        "  vectorizer = TfidfVectorizer(tokenizer=data_preprocess,stop_words=None, \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True,max_df=0.9,ngram_range=(1,2))\n",
        "  svd_model = TruncatedSVD(n_components=500,         \n",
        "                          algorithm='randomized',\n",
        "                          n_iter=10)\n",
        "  svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "                              ('svd', svd_model)])\n",
        "  dvecs=svd_transformer.fit_transform(docs)\n",
        "  wsim,vectorizer=get_wsim()\n",
        "  v=vectorizer.get_feature_names()\n",
        "  \n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  import random\n",
        "  for i in range(len(qrs)):\n",
        "    new_qr=qrs[i]\n",
        "    tkns=nltk.word_tokenize(qrs[i])\n",
        "    random.shuffle(tkns)\n",
        "    for x in tkns :\n",
        "      k2=k2-1\n",
        "      if k2<=0: break\n",
        "      if x not in stop_words:\n",
        "        try:\n",
        "          new_qr+=(' '+' '.join(getsyn(x,k1+1,v,wsim)[1:]))\n",
        "        except Exception:\n",
        "          pass\n",
        "    #if i<2:\n",
        "      #print('old-',qrs[i])\n",
        "      #print('new-',new_qr)\n",
        "      #print('\\n\\n')\n",
        "    qrs[i]=new_qr\n",
        "  from scipy.sparse import csr_matrix\n",
        "  #qvecs_qe=np.dot(vectorizer.transform(qrs).todense(),wsim)\n",
        "  #qvecs=np.dot(qvecs_qe,svd_model.components_.T)\n",
        "  qvecs=svd_transformer.transform(qrs)\n",
        "  #print(qvecs.shape)\n",
        "  A=sklearn.metrics.pairwise.cosine_similarity(qvecs,dvecs)\n",
        "  A=(A-A.min(axis=1).reshape(-1,1))/A.max(axis=1).reshape(-1,1)\n",
        "  pred_ids=np.zeros((255,k),dtype=int)\n",
        "  alpha=60.0/(70+60.0)\n",
        "  for i in range(0,tot_query):\n",
        "    doc_scores = bm25.get_scores(tokenized_query[i])\n",
        "    doc_scores = (doc_scores-doc_scores.min(axis=0))/doc_scores.max(axis=0)\n",
        "    A[i]=alpha*A[i]+(1-alpha)*doc_scores.reshape(1,-1)\n",
        "  for i in range(0,225):\n",
        "    x=np.argsort(A[i]).T[::-1][:k]\n",
        "    j=0\n",
        "    for y in x:\n",
        "      pred_ids[i][j]=dids[y]\n",
        "      j+=1\n",
        "  pdl=pred_ids.tolist()\n",
        "  qrels=json.load(open('/content/cranfield/cran_qrels.json', 'r'))\n",
        "  eval=Evaluation()\n",
        "  results=[]\n",
        "  for i in range(20):\n",
        "    s=i*10\n",
        "    e=s+10\n",
        "    results.append([eval.meanAveragePrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanNDCG(pdl[s:e],qids[s:e],qrels,k),eval.meanPrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanRecall(pdl[s:e],qids[s:e],qrels,k),eval.meanFscore(pdl[s:e],qids[s:e],qrels,k)])\n",
        "  #print('Using new method with bm25 and LSA- k: '+str(k)+' nDCG: '+str(eval.meanNDCG(pdl,qids,qrels,k)))\n",
        "  return results,eval.meanNDCG(pdl,qids,qrels,k),eval.meanAveragePrecision(pdl,qids,qrels,k),eval.meanRecall(pdl,qids,qrels,k),eval.meanFscore(pdl,qids,qrels,k),dvecs,svd_transformer,bm25,alpha,dids,docs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqN1-yCvr-a1",
        "cellView": "form"
      },
      "source": [
        "#@title Function for LSA with Query expansion\n",
        "def getsyn(x,k,v,wsim):\n",
        "  if x in v:\n",
        "    i= v.index(x)\n",
        "    y = np.argsort(wsim[i]).T[::-1][:k]\n",
        "    ans=[v[i] for i in y]\n",
        "    return ans\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "def train_new_qe(k,k1,k2):\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body']+' '+item['title'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  #print(len(dids),len(qids))\n",
        "  #k=5\n",
        "  vectorizer = TfidfVectorizer(tokenizer=data_preprocess,stop_words=None, \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True,max_df=0.6)\n",
        "  svd_model = TruncatedSVD(n_components=450,         \n",
        "                          algorithm='randomized',\n",
        "                          n_iter=10)\n",
        "  svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "                              ('svd', svd_model)])\n",
        "  dvecs=svd_transformer.fit_transform(docs)\n",
        "  wsim=sklearn.metrics.pairwise.cosine_similarity(svd_model.components_.T,svd_model.components_.T)\n",
        "  v=vectorizer.get_feature_names()\n",
        "  \n",
        "  stop_words = set(stopwords.words('english')) \n",
        "\n",
        "  for i in range(len(qrs)):\n",
        "    new_qr=qrs[i]\n",
        "    tkns=nltk.word_tokenize(qrs[i])\n",
        "    for x in tkns :\n",
        "      k2=k2-1\n",
        "      if k2<=0: break\n",
        "      if x not in stop_words:\n",
        "        try:\n",
        "          new_qr+=(' '+' '.join(getsyn(x,k1+1,v,wsim)[1:]))\n",
        "        except Exception:\n",
        "          pass\n",
        "    #if i<2:\n",
        "      #print('old-',qrs[i])\n",
        "      #print('new-',new_qr)\n",
        "      #print('\\n\\n')\n",
        "    qrs[i]=new_qr\n",
        "  from scipy.sparse import csr_matrix\n",
        "  #qvecs_qe=np.dot(vectorizer.transform(qrs).todense(),wsim)\n",
        "  #qvecs=np.dot(qvecs_qe,svd_model.components_.T)\n",
        "  qvecs=svd_transformer.transform(qrs)\n",
        "  #print(qvecs.shape)\n",
        "  A=sklearn.metrics.pairwise.cosine_similarity(qvecs,dvecs)\n",
        "  pred_ids=np.zeros((255,k),dtype=int)\n",
        "  for i in range(0,225):\n",
        "    x=np.argsort(A[i]).T[::-1][:k]\n",
        "    j=0\n",
        "    for y in x:\n",
        "      pred_ids[i][j]=dids[y]\n",
        "      j+=1\n",
        "  pdl=pred_ids.tolist()\n",
        "  qrels=json.load(open('/content/cranfield/cran_qrels.json', 'r'))\n",
        "  eval=Evaluation()\n",
        "  results=[]\n",
        "  for i in range(20):\n",
        "    s=i*10\n",
        "    e=s+10\n",
        "    results.append([eval.meanAveragePrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanNDCG(pdl[s:e],qids[s:e],qrels,k),eval.meanPrecision(pdl[s:e],qids[s:e],qrels,k)])\n",
        "  print('Using new method with query expansion- k: '+str(k)+' nDCG: '+str(eval.meanNDCG(pdl,qids,qrels,k)))\n",
        "  return results,eval.meanNDCG(pdl,qids,qrels,k),eval.meanAveragePrecision(pdl,qids,qrels,k),eval.meanRecall(pdl,qids,qrels,k),eval.meanFscore(pdl,qids,qrels,k)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgBZN_aS9kPa",
        "cellView": "form"
      },
      "source": [
        "#@title BM25 code\n",
        "def train_bm25(k):\n",
        "  import json\n",
        "  dj = json.load(open('/content/cranfield/cran_docs.json', 'r'))\n",
        "  docs,dids=[item['body']+' '+item['title'] for item in dj],[item['id'] for item in dj]\n",
        "  qj = json.load(open('/content/cranfield/cran_queries.json', 'r'))\n",
        "  qrs,qids=[item['query'] for item in qj],[item['query number'] for item in qj]\n",
        "  tot_query = len(qids)\n",
        "  pred_ids=np.zeros((tot_query,k),dtype=int)\n",
        "  tokenized_corpus = data_preprocess1(docs)\n",
        "  tokenized_query = data_preprocess1(qrs)\n",
        "  bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "  for i in range(0,tot_query):\n",
        "    doc_scores = bm25.get_scores(tokenized_query[i])\n",
        "    top_n = np.argsort(doc_scores)[::-1][:k]\n",
        "    index = 0\n",
        "    for j in top_n:\n",
        "      pred_ids[i][index]=dids[j]\n",
        "      index = index + 1\n",
        "  \n",
        "  pdl=pred_ids.tolist()\n",
        "  pdl\n",
        "  qrels=json.load(open('/content/cranfield/cran_qrels.json', 'r'))\n",
        "  eval=Evaluation()\n",
        "  results=[]\n",
        "  for i in range(20):\n",
        "    s=i*10\n",
        "    e=s+10\n",
        "    results.append([eval.meanAveragePrecision(pdl[s:e],qids[s:e],qrels,k),eval.meanNDCG(pdl[s:e],qids[s:e],qrels,k),eval.meanPrecision(pdl[s:e],qids[s:e],qrels,k)])\n",
        "  print('Using new method with bm25- k: '+str(k)+' nDCG: '+str(eval.meanNDCG(pdl,qids,qrels,k)))\n",
        "  rf=open('SVD_cosineSim.csv','w')\n",
        "  rf.write('MAP,NDCG,MP\\n')\n",
        "  for x in results:\n",
        "    rf.write(str(x[0])+','+str(x[1])+','+str(x[2])+'\\n')\n",
        "  rf.close()\n",
        "  return results,eval.meanNDCG(pdl,qids,qrels,k),eval.meanAveragePrecision(pdl,qids,qrels,k),eval.meanRecall(pdl,qids,qrels,k),eval.meanFscore(pdl,qids,qrels,k)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wW169DmBgaO1"
      },
      "source": [
        "#@title Statistcal Hypothesis testing code\n",
        "import numpy as np\n",
        "from statistics import variance\n",
        "from scipy import stats\n",
        "\n",
        "def test(x,y,a):\n",
        "  #null hypothesis: mean of x is less than or equal to mean of y\n",
        "  #alternate hypothesis: mean of x is greater than mean of y\n",
        "  n=len(x)\n",
        "  m=n\n",
        "  df=n+m-2\n",
        "  x_ , y_ = sum(x)/n, sum(y)/n\n",
        "  sx ,sy =variance(x),variance(y)\n",
        "  sp = ((n-1)*sx+(m-1)*sy)/(n+m-2)\n",
        "  ts = (x_ - y_)/(sp*(1/m+1/n))**0.5\n",
        "  z_a=stats.t.ppf(1-a,df)\n",
        "  print('x_:'+str(x_)+' y_:'+str(y_)+' sx :'+str(sx)+' sy: '+str(sy)+' sp: '+str(sp))\n",
        "  print('Test statistic: ',ts)\n",
        "  print('t-alpha: ',z_a)\n",
        "  print('p-value: ',1-stats.t.cdf(ts,df))\n",
        "  if ts>z_a:\n",
        "    print(\"mean of x is greater than mean of y (new method is better)\")\n",
        "  else:\n",
        "    print(\"No evidence for proving new method is better\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2reLXsJTKIK",
        "cellView": "form"
      },
      "source": [
        "#@title Custom query handler\n",
        "def custom_query(q,dvecs,svd,bm25,alpha,dids,docs,k,wsim,vectorizer,algo='mixed'):\n",
        "  from IPython.display import clear_output\n",
        "  clear_output(wait=True)\n",
        "  k1,k2=1,1\n",
        "  qrs=[q]\n",
        "  v=vectorizer.get_feature_names()\n",
        "  \n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  import random\n",
        "  for i in range(len(qrs)):\n",
        "    new_qr=qrs[i]\n",
        "    tkns=nltk.word_tokenize(qrs[i])\n",
        "    random.shuffle(tkns)\n",
        "    for x in tkns :\n",
        "      k2=k2-1\n",
        "      if k2<=0: break\n",
        "      if x not in stop_words:\n",
        "        try:\n",
        "          new_qr+=(' '+' '.join(getsyn(x,k1+1,v,wsim)[1:]))\n",
        "        except Exception:\n",
        "          pass\n",
        "    #if i<2:\n",
        "      #print('old-',qrs[i])\n",
        "      #print('new-',new_qr)\n",
        "      #print('\\n\\n')\n",
        "    qrs[i]=new_qr\n",
        "  from scipy.sparse import csr_matrix\n",
        "  #qvecs_qe=np.dot(vectorizer.transform(qrs).todense(),wsim)\n",
        "  #qvecs=np.dot(qvecs_qe,svd_model.components_.T)\n",
        "  qvecs=svd.transform([q])\n",
        "  tokenized_query = data_preprocess1([q])\n",
        "  A=sklearn.metrics.pairwise.cosine_similarity(qvecs,dvecs)\n",
        "  A=(A-A.min(axis=1).reshape(-1,1))/A.max(axis=1).reshape(-1,1)\n",
        "  B=bm25.get_scores(tokenized_query[0])\n",
        "  B = (B-B.min(axis=0))/B.max(axis=0)\n",
        "  if algo=='mixed':\n",
        "    alpha=60.0/(70.0+60.0)\n",
        "  elif algo=='lsa':\n",
        "    alpha=1\n",
        "  else:\n",
        "    alpha=0\n",
        "  A=alpha*A+(1-alpha)*B\n",
        "  pred_ids=np.zeros((255,1),dtype=int)\n",
        "  rel_docs=np.argsort(A).T[::-1][:k].reshape(1,-1)\n",
        "  print('Relevant documents:')\n",
        "  for j in range(k):print(dids[rel_docs[0][j]],end=' ')\n",
        "  print('\\n')\n",
        "  print('The contents of these documents are:')\n",
        "  c=1\n",
        "  for j in range(k):\n",
        "    print(str(c)+': '+docs[rel_docs[0][j]][:90]+'...')\n",
        "    c+=1\n",
        "  return"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279,
          "referenced_widgets": [
            "90897dfddb1c481babe140a44b4b8f71",
            "d7e350919d784be8af340073e431d1c7",
            "4da89f38ca8d4ac092d2913b1798d08e",
            "4281845ff53a41418f8dd17995863184",
            "2f83de012ae24037addd34b15c8dc142",
            "1967db895e0d4f3094c54b1ce24c80fd",
            "47f1db769d6a4ce1a0bec85bef6ec893",
            "dba0281c9a354505a9dfc974abcb5998",
            "b6d1cfb67df741b893fda4f22f8c71c0",
            "e7150060a8164aa69fcd312e1f22c63e",
            "3fea55e0e2bd496382e5d794e26b9374",
            "949eda08a0624c8ea9ae52e7025b285a",
            "b05715555552474ab3bf759a9964859e",
            "de8cc7c1534545a3bee602739d528b24",
            "39604baee01e402da407a3b5df22d845",
            "46383b8af63545bea81ad056e356c819"
          ]
        },
        "id": "YHoZGcfkbFfi",
        "cellView": "form",
        "outputId": "23d5901f-004d-4ea5-958e-d00da9729d8c"
      },
      "source": [
        "#@title GUI code\n",
        "#code for GUI\n",
        "res = train_mixed(2)\n",
        "wsim,vectorizer=get_wsim()\n",
        "dvecs,svd,bm25,alpha,dids,docs = res[5],res[6],res[7],res[8],res[9],res[10]\n",
        "import ipywidgets as widgets\n",
        "output = widgets.Output()\n",
        "TA=widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Your query',\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "dwl = widgets.Dropdown(\n",
        "    options=[('BM25', 1), ('BM25+LSA', 2), ('LSA', 3)],\n",
        "    value=1,\n",
        "    description='Algorithm: ',\n",
        ")\n",
        "\n",
        "dwl1 = widgets.Dropdown(\n",
        "    options=[('1', 1), ('2', 2), ('3', 3),('4',4),('5',5)],\n",
        "    value=3,\n",
        "    description='k:',\n",
        ")\n",
        "button = widgets.Button(\n",
        "    description='Search',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click me',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "      global wsim\n",
        "      q=TA.value\n",
        "      algo=dwl.value\n",
        "      k=dwl1.value\n",
        "      if algo==1:\n",
        "        custom_query(q,dvecs,svd,bm25,alpha,dids,docs,k,wsim,vectorizer,'bm25')\n",
        "      elif algo==2:\n",
        "        custom_query(q,dvecs,svd,bm25,alpha,dids,docs,k,wsim,vectorizer,'lsa')\n",
        "      else:\n",
        "        custom_query(q,dvecs,svd,bm25,alpha,dids,docs,k,wsim,vectorizer,'mixed')\n",
        "hb=widgets.VBox([TA,dwl,dwl1,button])\n",
        "button.on_click(on_button_clicked)       \n",
        "display(hb,output)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90897dfddb1c481babe140a44b4b8f71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Textarea(value='', placeholder='Your query'), Dropdown(description='Algorithm: ', options=(('BM…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39604baee01e402da407a3b5df22d845",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}